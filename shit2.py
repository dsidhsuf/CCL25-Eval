import json
import torch
import numpy as np
from sklearn.model_selection import train_test_split
from transformers import (
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
    DataCollatorForSeq2Seq,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    EarlyStoppingCallback,
    TrainerCallback
)
from datasets import Dataset
from tqdm import tqdm
import matplotlib.pyplot as plt

# ============================================
# ğŸ§© å››å…ƒç»„è§£æä¸è¯„ä¼°å‡½æ•°
# ============================================
def parse_quadruples(text):
    """
    å°†å½¢å¦‚ "(A1, B1, C1, D1); (A2, B2, C2, D2)" çš„æ–‡æœ¬
    è½¬ä¸º {("A1","B1","C1","D1"), ("A2","B2","C2","D2")}
    """
    quads = set()
    text = text.strip()
    if not text:
        return quads
    for part in text.split(";"):
        part = part.strip()
        if part.startswith("(") and part.endswith(")"):
            items = [x.strip() for x in part[1:-1].split(",")]
            if len(items) == 4:
                quads.add(tuple(items))
    return quads

def compute_quad_f1(preds, labels):
    """
    è®¡ç®—å››å…ƒç»„çº§åˆ«çš„ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1
    preds, labels: list of è§£ç åå­—ç¬¦ä¸²
    """
    assert len(preds) == len(labels)
    TP = FP = FN = 0
    for p_str, l_str in zip(preds, labels):
        p_set = parse_quadruples(p_str)
        l_set = parse_quadruples(l_str)
        TP += len(p_set & l_set)
        FP += len(p_set - l_set)
        FN += len(l_set - p_set)
    precision = TP / (TP + FP) if TP + FP > 0 else 0.0
    recall = TP / (TP + FN) if TP + FN > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0
    return {"precision": precision, "recall": recall, "f1": f1}

# ============================================
# âœ… ä¸»ä½“è„šæœ¬
# ============================================

# æ¨¡å‹é…ç½®
model_name = "Langboat/mengzi-t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# å¼ºåˆ¶ GPU
if not torch.cuda.is_available():
    raise RuntimeError("å¿…é¡»ä½¿ç”¨GPUè®­ç»ƒï¼Œè¯·æ£€æŸ¥CUDAç¯å¢ƒ")
device = torch.device("cuda")
model = model.to(device)

# åŠ è½½ JSON æ•°æ®
def load_json(path):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

# æ¸…æ´—æ•°æ®
def clean_data(data):
    return [d for d in data if d.get("content") and d.get("output") and d["output"].strip()]

# å¤„ç†è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®
all_data = clean_data(load_json("train.json"))
train_data, val_data = train_test_split(all_data, test_size=0.1, random_state=42)
test_data = load_json("test1.json")

train_ds = Dataset.from_list(train_data)
val_ds   = Dataset.from_list(val_data)
test_ds  = Dataset.from_list(test_data)

# åˆ†è¯å‡½æ•°
def tokenize_function(example):
    inputs = tokenizer(example["content"],
                       max_length=256, padding="max_length", truncation=True)
    with tokenizer.as_target_tokenizer():
        labs = tokenizer(example["output"],
                         max_length=256, padding="max_length", truncation=True)
    inputs["labels"] = [(t if t != tokenizer.pad_token_id else -100)
                        for t in labs["input_ids"]]
    return inputs

tokenized_train = train_ds.map(tokenize_function, batched=True)
tokenized_val   = val_ds.map(tokenize_function, batched=True)

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)

# æ—¥å¿—å­˜å‚¨
train_loss_list = []
eval_loss_list  = []
f1_score_list   = []

# compute_metrics
def compute_f1(eval_preds):
    preds, labels = eval_preds

    # å¦‚æœ preds æ˜¯ tupleï¼Œå–ç¬¬0é¡¹
    if isinstance(preds, tuple):
        preds = preds[0]

    # å°†æ‰€æœ‰å°äº 0 çš„ IDï¼ˆ-100ç­‰ï¼‰éƒ½æ›¿æ¢æˆ pad_token_id
    preds  = np.where(preds  >= 0, preds,  tokenizer.pad_token_id)
    labels = np.where(labels >= 0, labels, tokenizer.pad_token_id)

    # è§£ç 
    decoded_preds  = tokenizer.batch_decode(preds,  skip_special_tokens=True)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    decoded_preds  = [p.strip() for p in decoded_preds]
    decoded_labels = [l.strip() for l in decoded_labels]

    res = compute_quad_f1(decoded_preds, decoded_labels)
    return {"precision": res["precision"], "recall": res["recall"], "f1": res["f1"]}


# è‡ªå®šä¹‰ Callback è®°å½• loss & F1
class LogCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs and "loss" in logs:
            train_loss_list.append(logs["loss"])
    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        if metrics:
            eval_loss_list.append(metrics.get("eval_loss"))
            f1_score_list.append(metrics.get("eval_f1", 0.0))

# è®­ç»ƒå‚æ•°ï¼ˆç¡®ä¿ save_steps ä¸ eval_steps æ•´æ•°å€å…³ç³»ï¼‰
training_args = Seq2SeqTrainingArguments(
    output_dir="./results",
    evaluation_strategy="steps",
    eval_steps=100,
    logging_steps=10,
    save_steps=100,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=10,
    weight_decay=0.01,
    save_total_limit=2,
    predict_with_generate=True,
    fp16=True,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    greater_is_better=True,
    report_to="none"
)

trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_val,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_f1,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3), LogCallback()]
)

# å¼€å§‹è®­ç»ƒ
trainer.train()

# ä¿å­˜æ¨¡å‹
model.save_pretrained("./saved_model")
tokenizer.save_pretrained("./saved_model")

# ç»˜åˆ¶æ›²çº¿å›¾
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(train_loss_list, label="Train Loss")
plt.plot(range(0,len(train_loss_list),1), eval_loss_list, label="Eval Loss")
plt.xlabel("Logging Steps")
plt.ylabel("Loss")
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(0,len(f1_score_list)), f1_score_list, label="Eval F1")
plt.xlabel("Evaluation Steps")
plt.ylabel("F1 Score")
plt.legend()
plt.tight_layout()
plt.savefig("training_metrics.png")
plt.show()

# æ¨ç†å¹¶å†™å…¥ demo.txt
model.eval()
with open("demo.txt", "w", encoding="utf-8") as f:
    for item in tqdm(test_data):
        inputs = tokenizer(item["content"],
                           return_tensors="pt",
                           max_length=256,
                           truncation=True,
                           padding="max_length").to(device)
        outs = model.generate(**inputs,
                              max_length=256,
                              num_beams=5,
                              early_stopping=True)
        pred = tokenizer.decode(outs[0], skip_special_tokens=True).strip()
        if not pred.endswith("[END]"):
            pred += " [END]"
        f.write(pred + "\n")
